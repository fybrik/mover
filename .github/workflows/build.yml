name: Build

on:
  push:
    branches:
      - master
    tags:
      - '*'
  pull_request:
    branches:
      - master

env:
  DOCKER_HOSTNAME: ghcr.io

jobs:
  build:
    name: Build Spark
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
        - SPARK_VERSION: 2.4.8
          JAVA_VERSION: 8
          PROFILE: spark2
          TAG: latest-spark2
          RELEASE_TAG_SUFFIX: '-spark2'
        - SPARK_VERSION: 3.0.3
          JAVA_VERSION: 11
          PROFILE: spark3
          TAG: latest
          RELEASE_TAG_SUFFIX: ''
    steps:
      - uses: actions/checkout@v3.0.0
      - name: Set up JDK ${{ matrix.JAVA_VERSION }}
        uses: actions/setup-java@v2
        with:
          distribution: 'adopt'
          java-version: ${{ matrix.JAVA_VERSION }}
      - name: Cache Maven packages
        uses: actions/cache@v2.1.7
        with:
          path: |
            docker_images
            ~/.m2/repository
            ~/.zinc
            ~/.sbt
          key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}-docker${{ hashFiles('src/main/docker/spark/*') }}-${{ matrix.PROFILE }}
#          restore-keys: ${{ runner.os }}-m2
      - name: Build and test jars
        run: mvn -B package -Plocal-to-ghcr -P${{ matrix.PROFILE }}
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v2.1.0
        env:
          SPARK_VERSION: ${{ matrix.SPARK_VERSION }}
        with:
          flags: ${{ matrix.PROFILE }}
          env_vars: SPARK_VERSION
          fail_ci_if_error: false
          path_to_write_report: codecov_report.txt
          verbose: true
      - name: Debug
        run: ls -la docker_images || true
      - name: Recover Spark image from cache
        env:
          SPARK_VERSION: ${{ matrix.SPARK_VERSION }}
        run: ci/load_spark_base_cache.sh
      - name: Build Spark base image
        env:
          SPARK_VERSION: ${{ matrix.SPARK_VERSION }}
        run: docker build -t spark-base:${{ matrix.SPARK_VERSION }} -f src/main/docker/spark/${{ matrix.PROFILE }}.Dockerfile src/main/docker/spark --cache-from spark-base:${{ matrix.SPARK_VERSION }}
      - name: Save Spark image to cache
        env:
          SPARK_VERSION: ${{ matrix.SPARK_VERSION }}
        run: ci/store_spark_base_cache.sh
      - name: Build docker image with jib
        run: mvn -B jib:dockerBuild -Plocal-to-ghcr -P${{ matrix.PROFILE }}
      - name: Docker login
        if: ${{ github.event_name != 'pull_request' }}
        run: echo "${{ secrets.GITHUB_TOKEN }}" | docker login -u "${{ github.actor }}" --password-stdin "${{ env.DOCKER_HOSTNAME }}"
      - name: Docker push
        if: ${{ (github.event_name != 'pull_request') && !contains(github.ref, 'tags') }}
        run: docker push ghcr.io/fybrik/mover:${{ matrix.TAG }}
      - id: version
        name: Infer version
        run: echo ::set-output name=version::${GITHUB_REF#refs/*/}
      - name: Retag image for tag
        if: contains(github.ref, 'tags')
        run: docker tag ghcr.io/fybrik/mover:${{ matrix.TAG }} ghcr.io/fybrik/mover:${{ steps.version.outputs.version }}${{ matrix.RELEASE_TAG_SUFFIX }}
      - run: docker images
      - name: Push image for tag
        if: contains(github.ref, 'tags')
        run: docker push ghcr.io/fybrik/mover:${{ steps.version.outputs.version }}${{ matrix.RELEASE_TAG_SUFFIX }}
